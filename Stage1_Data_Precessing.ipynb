{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_datareader import data as pdr\n",
    "from datetime import datetime, timedelta\n",
    "from utils import status_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = \"2010-01-01\"\n",
    "END_DATE = \"2020-11-11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read raw data download from Quanel\n",
    "\n",
    "df_raw = pd.read_csv(r\"SHARADAR_SF1.csv\",index_col=\"calendardate\")\n",
    "#Filter only quarterly statement\n",
    "is_ARQ = df_raw['dimension'] == 'ARQ'\n",
    "df_Quarter = df_raw[is_ARQ]\n",
    "\n",
    "#Select factors, drop any rows with Null value\n",
    "df_selected_factor = df_Quarter[['ticker',\n",
    "    'eps','netinc','opinc','ncfo','cashnequsd',\n",
    "    'de','ebitda','fcf','marketcap','netmargin',\n",
    "    'pb','pe','ps','workingcapital','ev',\n",
    "    'divyield','fcfps','revenue','invcap', 'ebit', 'equityusd', 'assets']]\n",
    "    \n",
    "df_new = df_selected_factor.copy()\n",
    "df_new.dropna(axis=0, how=\"any\", inplace=True)\n",
    "\n",
    "#Caclulate ratio\n",
    "df_ratio = df_new[['equityusd','netinc','assets','invcap','ebit']]\n",
    "df_roe = pd.DataFrame(df_ratio['netinc'] / df_ratio['equityusd'], columns = ['roe'])\n",
    "df_roa = pd.DataFrame(df_ratio['netinc'] / df_ratio['assets'], columns = ['roa'])\n",
    "df_roic = pd.DataFrame(df_ratio['netinc'] / df_ratio['invcap'], columns = ['roic'])\n",
    "\n",
    "keystats_new = pd.concat([df_new, df_roe, df_roa, df_roic], axis =1)\n",
    "keystats_new.to_csv(\"keystats_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates the dataset containing S&P500 prices\n",
    "\n",
    "sp500_raw_data = pdr.get_data_yahoo(\"SPY\", start=START_DATE, end=END_DATE)\n",
    "sp500_raw_data.to_csv(\"sp500_index.csv\")\n",
    "\n",
    "sp500_raw_data_avg = sp500_raw_data.iloc[:,].rolling(window=60).mean()\n",
    "sp500_raw_data_avg.to_csv(\"sp500_index_avg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates the dataset containing all stock prices\n",
    "\n",
    "ticker_list = keystats_new.ticker.drop_duplicates().tolist()\n",
    "\n",
    "# Get all Adjusted Close prices for all the tickers in our list,\n",
    "# between START_DATE and END_DATE\n",
    "all_data = pdr.get_data_yahoo(ticker_list, start=START_DATE, end=END_DATE)\n",
    "stock_raw_data = all_data[\"Adj Close\"]\n",
    "\n",
    "# Remove any columns that hold no data, and print their tickers.\n",
    "stock_raw_data.dropna(how=\"all\", axis=1, inplace=True)\n",
    "missing_tickers = [\n",
    "    ticker for ticker in ticker_list if ticker.upper() not in stock_raw_data.columns\n",
    "]\n",
    "print(f\"{len(missing_tickers)} tickers are missing: \\n {missing_tickers} \")\n",
    "# If there are only some missing datapoints, forward fill.\n",
    "stock_raw_data.ffill(inplace=True)\n",
    "stock_raw_data.to_csv(\"stock_prices.csv\")\n",
    "\n",
    "# 5 business day/ week * 4 week/month * 3 month\n",
    "stock_raw_data_avg = stock_raw_data.iloc[:,].rolling(window=60).mean()\n",
    "stock_raw_data_avg.to_csv(\"stock_prices_avg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Currently, the sp500 and stock price datasets we downloaded do not have any data for\n",
    "days when the market was closed (weekends and public holidays). We need to amend this so that\n",
    "all rows are included. Doing this now saves a lot of effort when we actually create the\n",
    "keystats dataset, which requires that we have stock data every day.\n",
    ":return: SP500 and stock dataframes, with no missing rows.\n",
    "\"\"\"\n",
    "# Read in SP500 data and stock data, parsing the dates.\n",
    "sp500_raw_data = pd.read_csv(\"sp500_index_avg.csv\", index_col=\"Date\", parse_dates=True)\n",
    "stock_raw_data = pd.read_csv(\"stock_prices_avg.csv\", index_col=\"Date\", parse_dates=True)\n",
    "\n",
    "# We will reindex to include the weekends.\n",
    "start_date = str(stock_raw_data.index[0])\n",
    "end_date = str(stock_raw_data.index[-1])\n",
    "idx = pd.date_range(start_date, end_date)\n",
    "sp500_raw_data = sp500_raw_data.reindex(idx)\n",
    "stock_raw_data = stock_raw_data.reindex(idx)\n",
    "\n",
    "# Now the weekends are NaN, so we fill forward these NaNs\n",
    "# (i.e weekends take the value of Friday's adjusted close).\n",
    "sp500_raw_data.ffill(inplace=True)\n",
    "stock_raw_data.ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding stock price with keystat\n",
    "\n",
    "stock_price = []\n",
    "sp500_price = []\n",
    "stock_1m_price = []\n",
    "sp500_1m_price = []\n",
    "stock_p_change = []\n",
    "sp500_p_change = []\n",
    "for i in range(keystats_new.shape[0]):\n",
    "#for i in range(100):    \n",
    "    current_date = keystats_new.index[i]\n",
    "    one_month_date = datetime.strptime(keystats_new.index[i],\"%m/%d/%Y\") + timedelta(weeks = 4)\n",
    "    one_month_date = one_month_date.strftime(\"%m/%d/%Y\")\n",
    "    try:\n",
    "        stock_price_i = float(stock_raw_data.loc[current_date, keystats_new.ticker[i]])\n",
    "        stock_1m_price_i = float(stock_raw_data.loc[one_month_date, keystats_new.ticker[i]])\n",
    "        sp500_price_i = float(sp500_raw_data.loc[current_date, \"Adj Close\"])\n",
    "        sp500_1m_price_i = float(sp500_raw_data.loc[one_month_date, \"Adj Close\"])\n",
    "        stock_p_change_i = round(\n",
    "                ((stock_1m_price_i - stock_price_i) / stock_price_i * 100), 2\n",
    "        )\n",
    "        sp500_p_change_i = round(\n",
    "                ((sp500_1m_price_i - sp500_price_i) / sp500_price_i * 100), 2\n",
    "        )\n",
    "    except KeyError:\n",
    "        stock_price_i = None\n",
    "        stock_1m_price_i = None\n",
    "        sp500_price_i = None\n",
    "        sp500_1m_price_i = None\n",
    "        stock_p_change_i = None\n",
    "        sp500_p_change_i = None\n",
    "    stock_price.append(stock_price_i)\n",
    "    stock_1m_price.append(stock_1m_price_i)\n",
    "    sp500_price.append(sp500_price_i)\n",
    "    sp500_1m_price.append(sp500_1m_price_i)   \n",
    "    stock_p_change.append(stock_p_change_i)\n",
    "    sp500_p_change.append(sp500_p_change_i)\n",
    "    \n",
    "keystats_new[\"stock_price\"] = stock_price\n",
    "keystats_new[\"sp500_price\"] = sp500_price\n",
    "keystats_new[\"stock_p_change\"] = stock_p_change\n",
    "keystats_new[\"sp500_p_change\"] = sp500_p_change\n",
    "\n",
    "keystats_to_split = keystats_new.copy()\n",
    "keystats_to_split.dropna(axis=0, subset=[\"stock_price\", \"stock_p_change\"], inplace=True)\n",
    "keystats_to_split.to_csv(\"keystats_to_split.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list = keystats_to_split.ticker.drop_duplicates().tolist()\n",
    "lastest_keystat = pd.DataFrame() \n",
    "train_keystat = pd.DataFrame() \n",
    "for i in ticker_list:\n",
    "    try:\n",
    "        lastest_i = keystats_to_split.loc[keystats_to_split[\"ticker\"] == i].tail(1)\n",
    "        train_i = keystats_to_split.loc[keystats_to_split[\"ticker\"] == i].iloc[:-1]\n",
    "    except:\n",
    "        continue\n",
    "    lastest_keystat = lastest_keystat.append(lastest_i)\n",
    "    train_keystat = train_keystat.append(train_i)\n",
    "train_keystat.to_csv(\"ketstats_to_train.csv\", index = True)\n",
    "lastest_keystat.to_csv(\"forward_sample.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
