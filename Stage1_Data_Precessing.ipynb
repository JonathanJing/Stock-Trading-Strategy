{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_datareader import data as pdr\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(979843, 111)\n",
      "(2735, 4072)\n",
      "(48370, 31)\n",
      "(2063, 31)\n"
     ]
    }
   ],
   "source": [
    "print(pd.read_csv(r\"SHARADAR_SF1.csv\").shape)\n",
    "print(pd.read_csv(r\"stock_prices.csv\").shape)\n",
    "print(pd.read_csv(r\"ketstats_to_train.csv\").shape)\n",
    "print(pd.read_csv(r\"forward_sample.csv\").shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = \"2010-01-01\"\n",
    "END_DATE = \"2020-11-11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read raw data download from Quanel\n",
    "\n",
    "df_raw = pd.read_csv(r\"SHARADAR_SF1.csv\",index_col=\"calendardate\")\n",
    "#Filter only quarterly statement\n",
    "is_ARQ = df_raw['dimension'] == 'ARQ'\n",
    "df_Quarter = df_raw[is_ARQ]\n",
    "\n",
    "#The dataset contain too much factor, select only meanful factors\n",
    "df_selected_factor = df_Quarter[['ticker',\n",
    "    'eps','netinc','opinc','ncfo','cashnequsd',\n",
    "    'de','ebitda','fcf','marketcap','netmargin',\n",
    "    'pb','pe','ps','workingcapital','ev',\n",
    "    'divyield','fcfps','revenue','invcap', 'ebit', 'equityusd', 'assets']]\n",
    "\n",
    "#Filter tickers with market cap larger than 1 billion\n",
    "is_1m =  df_selected_factor['marketcap']>=1000000000\n",
    "data_mktcp = df_selected_factor[is_1m]\n",
    "\n",
    "#Drop any rows with Null value\n",
    "df_new = data_mktcp.copy()\n",
    "df_new.dropna(axis=0, how=\"any\", inplace=True)\n",
    "\n",
    "#Caclulate ratio\n",
    "df_ratio = df_new[['equityusd','netinc','assets','invcap','ebit']]\n",
    "df_roe = pd.DataFrame(df_ratio['netinc'] / df_ratio['equityusd'], columns = ['roe'])\n",
    "df_roa = pd.DataFrame(df_ratio['netinc'] / df_ratio['assets'], columns = ['roa'])\n",
    "df_roic = pd.DataFrame(df_ratio['netinc'] / df_ratio['invcap'], columns = ['roic'])\n",
    "\n",
    "keystats_new = pd.concat([df_new, df_roe, df_roa, df_roic], axis =1)\n",
    "keystats_new.to_csv(\"keystats_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates the dataset containing S&P500 prices\n",
    "\n",
    "sp500_raw_data = pdr.get_data_yahoo(\"SPY\", start=START_DATE, end=END_DATE)\n",
    "sp500_raw_data.to_csv(\"sp500_index.csv\")\n",
    "\n",
    "sp500_raw_data_avg = sp500_raw_data.iloc[:,].rolling(window=60).mean()\n",
    "sp500_raw_data_avg.to_csv(\"sp500_index_avg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates the dataset containing all stock prices\n",
    "\n",
    "ticker_list = keystats_new.ticker.drop_duplicates().tolist()\n",
    "\n",
    "ticker_list = pd.read_csv(\"ketstats_to_train.csv\", index_col=\"calendardate\")\n",
    "ticker_list.dropna(axis=0, how=\"any\", inplace=True)\n",
    "\n",
    "features = ticker_list.columns[1:-4]\n",
    "#X = ticker_list[features].values\n",
    "X = pd.DataFrame(ticker_list[features])\n",
    "\n",
    "# The labels are generated by applying the status_calc to the dataframe.\n",
    "# '1' if a stock beats the S&P500 by more than x%, else '0'. Here x is the\n",
    "# outperformance parameter, which is set to 10 by default but can be redefined.\n",
    "y = pd.DataFrame(list(\n",
    "        status_calc(\n",
    "            ticker_list[\"stock_p_change\"], ticker_list[\"sp500_p_change\"], outperformance=10\n",
    "        )\n",
    "    ))\n",
    "\n",
    "# z is required for us to track returns\n",
    "z = np.array(ticker_list[[\"stock_p_change\", \"sp500_p_change\"]])\n",
    "\n",
    "# Generate the train set and test set by randomly splitting the dataset\n",
    "X_train, X_test, y_train, y_test, z_train, z_test = train_test_split(\n",
    "    X, y, z, test_size=0.1\n",
    ")\n",
    "\n",
    "# Instantiate a RandomForestClassifier with 100 trees, then fit it to the training data\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n"
    "y_pred = clf.predict(X_test)\n",
    "print(\"Classifier performance\\n\", \"=\" * 20)\n",
    "print(f\"Accuracy score: {clf.score(X_test, y_test): .2f}\")\n",
    "print(f\"Precision score: {precision_score(y_test, y_pred): .2f}\")\n",
    "\n",
    "# Get all Adjusted Close prices for all the tickers in our list,\n",
    "# between START_DATE and END_DATE\n",
    "all_data = pdr.get_data_yahoo(ticker_list, start=START_DATE, end=END_DATE)\n",
    "stock_raw_data = all_data[\"Adj Close\"]\n",
    "\n",
    "# Remove any columns that hold no data, and print their tickers.\n",
    "stock_raw_data.dropna(how=\"all\", axis=1, inplace=True)\n",
    "missing_tickers = [\n",
    "    ticker for ticker in ticker_list if ticker.upper() not in stock_raw_data.columns\n",
    "]\n",
    "print(f\"{len(missing_tickers)} tickers are missing: \\n {missing_tickers} \")\n",
    "# If there are only some missing datapoints, forward fill.\n",
    "stock_raw_data.to_csv(\"stock_prices.csv\")\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Currently, the sp500 and stock price datasets we downloaded do not have any data for\n",
    "days when the market was closed (weekends and public holidays). We need to amend this so that\n",
    "all rows are included. Doing this now saves a lot of effort when we actually create the\n",
    "keystats dataset, which requires that we have stock data every day.\n",
    ":return: SP500 and stock dataframes, with no missing rows.\n",
    "\"\"\"\n",
    "# Read in SP500 data and stock data, parsing the dates.\n",
    "sp500_raw_data = pd.read_csv(\"sp500_index_avg.csv\", index_col=\"Date\", parse_dates=True)\n",
    "stock_raw_data = pd.read_csv(\"stock_prices_avg.csv\", index_col=\"Date\", parse_dates=True)\n",
    "\n",
    "# We will reindex to include the weekends.\n",
    "start_date = str(stock_raw_data.index[0])\n",
    "end_date = str(stock_raw_data.index[-1])\n",
    "idx = pd.date_range(start_date, end_date)\n",
    "sp500_raw_data = sp500_raw_data.reindex(idx)\n",
    "stock_raw_data = stock_raw_data.reindex(idx)\n",
    "\n",
    "# Now the weekends are NaN, so we fill forward these NaNs\n",
    "# (i.e weekends take the value of Friday's adjusted close).\n",
    "sp500_raw_data.ffill(inplace=True)\n",
    "stock_raw_data.ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding stock price with keystat\n",
    "\n",
    "stock_price = []\n",
    "sp500_price = []\n",
    "stock_1m_price = []\n",
    "sp500_1m_price = []\n",
    "stock_p_change = []\n",
    "sp500_p_change = []\n",
    "for i in range(keystats_new.shape[0]):\n",
    "#for i in range(100):    \n",
    "    current_date = keystats_new.index[i]\n",
    "    one_month_date = datetime.strptime(keystats_new.index[i],\"%m/%d/%Y\") + timedelta(weeks = 4)\n",
    "    one_month_date = one_month_date.strftime(\"%m/%d/%Y\")\n",
    "    try:\n",
    "        stock_price_i = float(stock_raw_data.loc[current_date, keystats_new.ticker[i]])\n",
    "        stock_1m_price_i = float(stock_raw_data.loc[one_month_date, keystats_new.ticker[i]])\n",
    "        sp500_price_i = float(sp500_raw_data.loc[current_date, \"Adj Close\"])\n",
    "        sp500_1m_price_i = float(sp500_raw_data.loc[one_month_date, \"Adj Close\"])\n",
    "        stock_p_change_i = round(\n",
    "                ((stock_1m_price_i - stock_price_i) / stock_price_i * 100), 2\n",
    "        )\n",
    "        sp500_p_change_i = round(\n",
    "                ((sp500_1m_price_i - sp500_price_i) / sp500_price_i * 100), 2\n",
    "        )\n",
    "    except KeyError:\n",
    "        stock_price_i = None\n",
    "        stock_1m_price_i = None\n",
    "        sp500_price_i = None\n",
    "        sp500_1m_price_i = None\n",
    "        stock_p_change_i = None\n",
    "        sp500_p_change_i = None\n",
    "        \n",
    "    stock_price.append(stock_price_i)\n",
    "    stock_1m_price.append(stock_1m_price_i)\n",
    "    sp500_price.append(sp500_price_i)\n",
    "    sp500_1m_price.append(sp500_1m_price_i)   \n",
    "    stock_p_change.append(stock_p_change_i)\n",
    "    sp500_p_change.append(sp500_p_change_i)\n",
    "    \n",
    "keystats_new[\"stock_price\"] = stock_price\n",
    "keystats_new[\"sp500_price\"] = sp500_price\n",
    "keystats_new[\"stock_p_change\"] = stock_p_change\n",
    "keystats_new[\"sp500_p_change\"] = sp500_p_change\n",
    "\n",
    "keystats_to_split = keystats_new.copy()\n",
    "keystats_to_split.dropna(axis=0, subset=[\"stock_price\", \"stock_p_change\"], inplace=True)\n",
    "keystats_to_split.to_csv(\"keystats_to_split.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    ,
    "lastest_keystat = pd.DataFrame() \n",
    "train_keystat = pd.DataFrame() \n",
    "for i in ticker_list:\n",
    "    try:\n",
    "        lastest_i = keystats_to_split.loc[keystats_to_split[\"ticker\"] == i].tail(1)\n",
    "        train_i = keystats_to_split.loc[keystats_to_split[\"ticker\"] == i].iloc[:-1]\n",
    "    except:\n",
    "        continue\n",
    "    lastest_keystat = lastest_keystat.append(lastest_i)\n",
    "    train_keystat = train_keystat.append(train_i)\n",
    "train_keystat.to_csv(\"ketstats_to_train.csv\", index = True)\n",
    "lastest_keystat.to_csv(\"forward_sample.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
